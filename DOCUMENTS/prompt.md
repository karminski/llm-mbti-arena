我想制作一个大模型MBTI测试项目，使用MBTI测试题询问大模型，并最终得出目标大模型的人格类型，项目名字叫 llm-mbti-arena，项目分为这几个部分：

1. MBTI测试题目，我已经准备好了，在这里  #mbti-questions.json 

2. benchmark 程序，TypeScript 编写，是一个命令行程序，编译后名称为 llmmbti



benchmark 程序功能如下：

1. 支持设定环境变量 LLMMBIT_API, 该变量指定使用的OpenAI风格的大模型API地址

2. 支持设定环境变量 LLMMBIT_API_KEY, 该变量指定使用的OpenAI风格的大模型API地址的API密钥

3. 支持设定环境变量 LLMMBIT_API_MODEL, 变量指定使用的模型名称, 例如"openai/gpt-4o"

4. 直接运行命令或者 --help 参数打印帮助信息

5. --bench 命令开始测试并输出测试进度

6. 测试过程中展示目前进行的题目编号，测试进度条，目前的大模型的MBTI人格累计数据，即 E - 外向型, I - 内向型, S - 感觉型, N - 直觉型, T - 思考型, F - 感情型, J - 判断型, P - 感知型。并根据实时的数据累计展示当前大模型更倾向于16人格的哪种类型。

7. 测试结束后给出报告，包括大模型的每种人格的百分比和最终人格类型

8. --json-report 参数输出json报告结果，包括模型名称，测试时间，每道题的回答选项，每个人格的百分比，最终人格类型。

9. benchmark 程序架构上需要作一定程度上的设计，我们API调用使用openai库即可，不需要自己实现。程序的测试运行部分和进度渲染部分需要按模块分开。
